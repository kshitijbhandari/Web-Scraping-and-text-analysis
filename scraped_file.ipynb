{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09128a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88fd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file_path ='Input.xlsx - Sheet1.csv'\n",
    "links_list = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    " \n",
    "    next(csv_reader)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        if len(row) >= 2:\n",
    "            links_list.append(row[1])\n",
    "\n",
    "# Print the list of values\n",
    "# print(links_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301609fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_id_dict = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    csv_dict = csv.DictReader(file)\n",
    "    for row in csv_dict:\n",
    "            url_id_dict[row['URL']] = row['URL_ID']\n",
    "\n",
    "# Print the dictionary\n",
    "# print(url_id_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d673f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'scraped_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63487b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_chars_from_string(input_string, chars_to_remove):\n",
    "    for char in chars_to_remove:\n",
    "        input_string = input_string.replace(char, '')\n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f41a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_remove = ['/','\\\\','*','?','<','>',':']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298f7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper (link):\n",
    "    \n",
    "    url_id = url_id_dict.get(link)\n",
    "    webpage = requests.get(link).text\n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "    title = soup.find_all('h1')[0].text\n",
    "#     title_list.append(title)\n",
    "    \n",
    "    main_div = soup.find('div', class_= 'td-theme-wrap',id = 'td-outer-wrap')\n",
    "    if main_div:\n",
    "        # Extract text from the p tags inside the parent div\n",
    "        all_text = [p.get_text(strip=True) for p in main_div.find_all('p')]\n",
    "\n",
    "        # Define the lines to exclude\n",
    "        lines_to_exclude = ['NLP-based Approach for Data Transformation',\n",
    "                            'An ETL tool to pull data from Shiphero to Google Bigquery Data Warehouse',\n",
    "                            'Plaid Financial Analytics – A Data-Driven Dashboard to generate insights',\n",
    "                            'Recommendation Engine for Insurance Sector to Expand Business in the Rural Area',\n",
    "                            'Grafana Dashboard – Oscar Awards',\n",
    "                            'AutoGPT Setup',\n",
    "                            'Playstore & Appstore to Google Analytics (GA) or Firebase to Google Data Studio Mobile App KPI Dashboard',\n",
    "                            'Google Local Service Ads LSA API To Google BigQuery to Google Data Studio',\n",
    "                            'Rise of telemedicine and its Impact on Livelihood by 2040',\n",
    "                            'Rise of e-health and its impact on humans by the year 2030',\n",
    "                            'Rise of e-health and its impact on humans by the year 2030',\n",
    "                            'Rise of telemedicine and its Impact on Livelihood by 2040',\n",
    "                            'AI/ML and Predictive Modeling',\n",
    "                            'Solution for Contact Centre Problems',\n",
    "                            'How to Setup Custom Domain for Google App Engine Application?',\n",
    "                            'Code Review Checklist',\n",
    "                           'Contact us:hello@blackcoffer.com',\n",
    "                            '© All Right Reserved, Blackcoffer(OPC) Pvt. Ltd']\n",
    "\n",
    "        # Filter out the excluded lines\n",
    "        filtered_text = [line for line in all_text if line not in lines_to_exclude]\n",
    "\n",
    "        # Join the filtered lines back into a single string\n",
    "        filtered_text = ' '.join(filtered_text)\n",
    "        \n",
    "        final_text = ' '.join([title,filtered_text])\n",
    "        \n",
    "        filename = link+'_'+url_id\n",
    "#         print(filename)\n",
    "        filename_filtered = remove_chars_from_string(filename, characters_to_remove)\n",
    "        final_filename = f\"{filename_filtered}.txt\"\n",
    "#         print(filename_filtered)\n",
    "        file_name = os.path.join(folder_name, final_filename)\n",
    "        with open(file_name,'w',encoding = 'utf-8') as f:\n",
    "            f.write(final_text)\n",
    "            f.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b68dd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89404859",
   "metadata": {},
   "source": [
    "After studying I found thatfollowing URL's are not working\n",
    "1.https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
    "2.https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
    "3.https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac695034",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_del = [107,20,7]\n",
    "for index in indices_to_del:\n",
    "    del links_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f99302b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7518b6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [04:31<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271.9108440876007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for link in tqdm(links_list):\n",
    "    scraper(link)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
